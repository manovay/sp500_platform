{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf5d956-929e-49f5-8f02-0ceee662f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --quiet --upgrade torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118 typing_extensions bitsandbytes transformers peft accelerate psycopg2-binary pandas tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708b01f-0fdc-420e-b2b6-cadc460e315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# Chat-format tokens\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS,  E_SYS  = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a portfolio optimization assistant.\\n\\n\"\n",
    "    \"Given a stock's profile, fundamen  tals, sentiment, and its current allocation weight in a portfolio, \"\n",
    "    \"recommend how the allocation should be adjusted.\\n\\n\"\n",
    "    \"Output format:\\n\"\n",
    "    \"- Verdict: <Increase|Decrease|Hold|Add|Remove>\\n\"\n",
    "    \"- New Allocation: <X.XX>%\\n\"\n",
    "    \"- Reasoning: <short explanation>\\n\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147f670-1bf0-4faa-84d2-4cae4509e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers: (503, 4)\n",
      "Prices: (376682, 7)\n",
      "Labels: (503, 11)\n",
      "Estimates: (3704, 23)\n",
      "Grades: (17815, 7)\n",
      "Metrics: (1509, 3)\n",
      "Profiles: (503, 3)\n",
      "News: (21350, 9)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Load CSVs and pick one ticker\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "tickers_df = pd.read_csv(\n",
    "    \"tickers.csv\",\n",
    "    parse_dates=[\"date_added\"]\n",
    ")\n",
    "\n",
    "# 2) Prices\n",
    "prices_df = pd.read_csv(\n",
    "    \"prices.csv\",\n",
    "    parse_dates=[\"price_date\"]\n",
    ")\n",
    "\n",
    "# 3) Analyst labels\n",
    "labels_df = pd.read_csv(\n",
    "    \"analyst_labels.csv\",\n",
    "    parse_dates=[\"label_date\"]\n",
    ")\n",
    "\n",
    "# 4) Analyst estimates\n",
    "estimates_df = pd.read_csv(\n",
    "    \"analyst_estimates.csv\",\n",
    "    parse_dates=[\"report_date\"]\n",
    ")\n",
    "\n",
    "# 5) Historical grades\n",
    "grades_df = pd.read_csv(\n",
    "    \"grades_historical.csv\",\n",
    "    parse_dates=[\"rating_date\"]\n",
    ")\n",
    "\n",
    "# 6) Key metrics (JSON-encoded column)\n",
    "metrics_df = pd.read_csv(\n",
    "    \"key_metrics.csv\",\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "# use json.loads for the JSON column\n",
    "profiles_df    = pd.read_csv(\n",
    "    \"profiles.csv\",\n",
    "    converters={\"profile_data\": lambda x: json.loads(x)}\n",
    ")\n",
    "news_df = pd.read_csv(\n",
    "    \"stock_news.csv\",\n",
    "    parse_dates=[\"published_date\"]\n",
    ")\n",
    "allocations_df = pd.read_csv(\"allocations.csv\", parse_dates=[\"allocation_date\"])\n",
    "# Quick sanity-check\n",
    "print(\"Tickers:\",      tickers_df.shape)\n",
    "print(\"Prices:\",       prices_df.shape)\n",
    "print(\"Labels:\",       labels_df.shape)\n",
    "print(\"Estimates:\",    estimates_df.shape)\n",
    "print(\"Grades:\",       grades_df.shape)\n",
    "print(\"Metrics:\",      metrics_df.shape)\n",
    "print(\"Profiles:\",     profiles_df.shape)\n",
    "print(\"News:\",         news_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedb8ea-46a1-4ae6-9bca-e8a6a04994ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_price_stats(df, since):\n",
    "    sub = df[df.price_date >= since]\n",
    "    if len(sub) < 2:\n",
    "        return \"  Insufficient data\"\n",
    "    change = (sub.close_price.iloc[-1] / sub.close_price.iloc[0] - 1) * 100\n",
    "    hi, lo = sub.high_price.max(), sub.low_price.min()\n",
    "    avg_vol = int(sub.volume.mean())\n",
    "    return (f\"  Change: {change:.2f}% | High: {hi:.2f} | Low: {lo:.2f} | \"\n",
    "            f\"Avg Vol: {avg_vol}\")\n",
    "\n",
    "def _top_news(df, since, n=2):\n",
    "    sub = df[df.published_date >= since].sort_values(\"published_date\", ascending=False).head(n)\n",
    "    if sub.empty:\n",
    "        return [\"  No news\"]\n",
    "    return [f\"  [Headline]: {r.title}\\n  [Summary]: {r.text}\"\n",
    "            for _, r in sub.iterrows()]\n",
    "\n",
    "def _latest_label(df, since):\n",
    "    sub = df[df.label_date >= since].sort_values(\"label_date\", ascending=False)\n",
    "    if sub.empty:\n",
    "        return \"  No recent analyst rating\"\n",
    "    r = sub.iloc[0]\n",
    "    return (f\"  Rating: {r.rating} (Score {r.overall_score}/5) on {r.label_date.date()}\")\n",
    "\n",
    "def _latest_estimate(df, since):\n",
    "    sub = df[df.report_date >= since].sort_values(\"report_date\", ascending=False)\n",
    "    if sub.empty:\n",
    "        return \"  No recent estimates\"\n",
    "    e = sub.iloc[0]\n",
    "    return (f\"  EPS Avg: {e.eps_avg:.2f} | Revenue Avg: {e.revenue_avg:,} \"\n",
    "            f\"on {e.report_date.date()}\")\n",
    "\n",
    "def get_previous_allocation(ticker, alloc_df):\n",
    "    \"\"\"Returns most recent allocation percent for ticker, or 0.00 if not found.\"\"\"\n",
    "    try:\n",
    "        latest = (\n",
    "            alloc_df[alloc_df[\"ticker\"] == ticker]\n",
    "            .sort_values(\"allocation_date\", ascending=False)\n",
    "            .iloc[0]\n",
    "        )\n",
    "        return round(float(latest[\"allocation_pct\"]) * 100, 2)\n",
    "    except:\n",
    "        return 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d6f3dbd-525a-4918-a2e4-636ffc9e61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def build_weekly_block(ticker):\n",
    "    today = pd.to_datetime(\"today\").normalize()\n",
    "    since = today - timedelta(days=7)\n",
    "\n",
    "    stats = _compute_price_stats(prices_df[prices_df.ticker==ticker], since)\n",
    "    news  = _top_news   (news_df[news_df.symbol==ticker], since)\n",
    "    label = _latest_label(labels_df[labels_df.ticker==ticker], since)\n",
    "    est   = _latest_estimate(estimates_df[estimates_df.symbol==ticker], since)\n",
    "\n",
    "    lines = [\n",
    "        \"### Weekly Outlook\",\n",
    "        stats,\n",
    "        *news,\n",
    "        label,\n",
    "        est,\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def build_quarterly_block(ticker):\n",
    "    today = pd.to_datetime(\"today\").normalize()\n",
    "    since = today - timedelta(days=90)\n",
    "\n",
    "    stats = _compute_price_stats(prices_df[prices_df.ticker==ticker], since)\n",
    "    news  = _top_news   (news_df[news_df.symbol==ticker], since)\n",
    "    label = _latest_label(labels_df[labels_df.ticker==ticker], since)\n",
    "    est   = _latest_estimate(estimates_df[estimates_df.symbol==ticker], since)\n",
    "\n",
    "    lines = [\n",
    "        \"### Quarterly Outlook\",\n",
    "        stats,\n",
    "        *news,\n",
    "        label,\n",
    "        est,\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def build_yearly_block(ticker):\n",
    "    today = pd.to_datetime(\"today\").normalize()\n",
    "    since = today - timedelta(days=365)\n",
    "\n",
    "    stats = _compute_price_stats(prices_df[prices_df.ticker==ticker], since)\n",
    "    news  = _top_news   (news_df[news_df.symbol==ticker], since)\n",
    "    label = _latest_label(labels_df[labels_df.ticker==ticker], since)\n",
    "    est   = _latest_estimate(estimates_df[estimates_df.symbol==ticker], since)\n",
    "\n",
    "    lines = [\n",
    "        \"### Yearly Outlook\",\n",
    "        stats,\n",
    "        *news,\n",
    "        label,\n",
    "        est,\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e3fcd-6b8d-4a95-a6d8-5cb49c2db99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are a seasoned stock market analyst.\n",
      "\n",
      "First, issue a single “Verdict:” line, choosing one of “Buy”, “Hold”, or “Sell” for the stock based on the aggregated data below.\n",
      "\n",
      "Then, under separate headings, provide your rationale for that verdict over three timeframes:\n",
      "  • Weekly Rationale\n",
      "  • Quarterly Rationale\n",
      "  • Yearly Rationale\n",
      "\n",
      "For each timeframe, use:\n",
      "  1. 3 bullet points of key price‐movement statistics (change %, high/low, avg volume)\n",
      "  2. 2 news headlines with summaries\n",
      "  3. 1–2 sentences tying those points back to your overall Verdict\n",
      "\n",
      "Label your response exactly as:\n",
      "Ve …\n"
     ]
    }
   ],
   "source": [
    "def build_full_prompt(ticker):\n",
    "    # optional: include company profile\n",
    "    prof = profiles_df[profiles_df.ticker==ticker].profile_data.iloc[0]\n",
    "    prev_alloc = get_previous_allocation(ticker, allocations_df)\n",
    "    intro = (\n",
    "        f\"[Company]: {ticker} — {prof.get('companyName', '')}, \"\n",
    "        f\"Sector: {prof.get('sector', '')}\\n\"\n",
    "        f\"Previous Allocation: {prev_alloc:.2f}%\\n\\n\"\n",
    "    )\n",
    "    blocks = [\n",
    "        intro,\n",
    "        build_weekly_block(ticker),\n",
    "        \"\",\n",
    "        build_quarterly_block(ticker),\n",
    "        \"\",\n",
    "        build_yearly_block(ticker),\n",
    "    ]\n",
    "    body = \"\\n\\n\".join(blocks)\n",
    "    return f\"{B_INST} {B_SYS}{SYSTEM_PROMPT}{E_SYS}{body}{E_INST}\"\n",
    "\n",
    "# Test\n",
    "print(build_full_prompt(\"AAPL\")[:600], \"…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188fbdc-5fac-4095-9851-2e594569af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "The token `sp500` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os; os.environ[\"HF_TOKEN\"] = \n",
    "!pip install --quiet huggingface_hub && huggingface-cli login --token \"$HF_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889ce94b-7afc-435c-85c9-61583e039eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646c188ab49d45e881a25556c912110b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e27c53ec74462abc53eec33b1ba70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0b94ab560847ab993a8eaec893fd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a844f45cffd648caa2434f1ad6d3e962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a6f196ed44488c8d616aaa54e1861c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5865fd07fb4c659fc21c9341f0979a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c479bcd8e4e4e1494e2e42957700aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb2fa764ac5405687f296fe1fc84206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fff14fa75641dc872315d9b264238b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88ac96df66542748c332310bd3ab41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9732d3703f3f4d4a9977273130c92d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04a0776f5804b0096308d168ab19c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/528 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e442a3f69f4b40af7a3b8558f7f595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/40.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell X — Load model in FP16 (requires ~14 GB VRAM)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft         import PeftModel\n",
    "\n",
    "# 1) Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2) Base model in FP16\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 3) Attach your LoRA adapter\n",
    "model = PeftModel.from_pretrained(\n",
    "    base,\n",
    "    \"FinGPT/fingpt-forecaster_dow30_llama2-7b_lora\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb38650f-4421-4a3a-b205-66ee26912737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Response:**\n",
       "\n",
       "[Verdict: Buy]\n",
       "\n",
       "Weekly Rationale:\n",
       "\n",
       "* The weekly performance of Apple has seen an increase in price by 1.34%.\n",
       "* The high of 206.00 suggests bullish sentiment.\n",
       "* The average volume of 62700140 shows strong investor interest, which is a positive sign.\n",
       "\n",
       "Quarterly Rationale:\n",
       "\n",
       "* Over the quarter, Apple saw a significant increase in price by 7.66%, indicating a strong upward trend.\n",
       "* The high of 225.62 indicates continued strength in the stock, while the low of 169.21 shows some consolidation.\n",
       "* The average volume of 61671595 suggests consistent investment in the stock and a growing following among institutional investors.\n",
       "\n",
       "Yearly Rationale:\n",
       "\n",
       "* Over the year, the performance of Apple has been excellent, with a rise of 9.00%. This strong uptrend suggests that investors have confidence in the long-term prospects of the company, leading them to buy more shares.\n",
       "* The high of 260.10 shows a clear potential for further growth, particularly if Apple can continue to innovate and expand its product line.\n",
       "* Despite tepid AI impact and valuation issues, the company's solid financial position, evident from EPS Avg and Revenue Avg, provides evidence of robust fundamentals and long-term growth potential. \n",
       "\n",
       "Therefore, considering the current performance and the overall outlook for the next quarter and year, I would recommend a \"Buy\" rating for Apple stocks. However, it's important to monitor the situation closely and make adjustments accordingly based on market developments. \n",
       "\n",
       "The recent WWDC announcement and WhatsApp's joining in the legal challenge against the U.K. government's demand may also signal potential opportunities for future growth. Therefore, there is upside potential in Apple's stock price, especially if the company continues to make strategic moves like these. \n",
       "\n",
       "However, as mentioned earlier, AI impact and valuation concerns still need to be watched closely, as they could potentially negatively affect the share prices if not adequately addressed. Thus, caution remains essential when dealing with volatile markets. Overall, buying at this point appears promising, but one must stay vigilant about future market developments"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 2) Tokenize with truncation & padding\n",
    "prompt = build_full_prompt(\"AAPL\")\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length=model.config.max_position_embeddings,\n",
    "    padding=\"longest\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "eos_id = tokenizer.eos_token_id\n",
    "with torch.no_grad():\n",
    "    out_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        min_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.1,\n",
    "        eos_token_id=eos_id,\n",
    "        pad_token_id=eos_id,\n",
    "        early_stopping=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "# 4) Decode & strip off everything before the model’s actual response\n",
    "raw = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "response = raw.split(\"[/INST]\")[-1].strip()\n",
    "\n",
    "# 5) Show it in Markdown for readability\n",
    "display(Markdown(f\"**Response:**\\n\\n{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7665328f-0770-4f3c-ac48-ab3ce630ea16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mticker\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: response}])\n\u001b[1;32m      2\u001b[0m out_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved prompt+response → output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    }
   ],
   "source": [
    "out_df = pd.DataFrame([{\"ticker\": ticker, \"prompt\": prompt, \"response\": response}])\n",
    "out_df.to_csv(\"output.csv\", index=False)\n",
    "print(\"Saved prompt+response → output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e07957-f14e-4396-bed5-cd3284293bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
